{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:14:42.341879Z",
     "iopub.status.busy": "2023-06-03T00:14:42.339862Z",
     "iopub.status.idle": "2023-06-03T00:15:08.457776Z",
     "shell.execute_reply": "2023-06-03T00:15:08.456108Z",
     "shell.execute_reply.started": "2023-06-03T00:14:42.341775Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# General imports.\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Specific imports.\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_scheduler, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:33.140885Z",
     "iopub.status.busy": "2023-06-03T00:15:33.140176Z",
     "iopub.status.idle": "2023-06-03T00:15:36.638601Z",
     "shell.execute_reply": "2023-06-03T00:15:36.636573Z",
     "shell.execute_reply.started": "2023-06-03T00:15:33.140828Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/mbti-tweets/cleaned_df.csv\")\n",
    "data = data.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:39.072366Z",
     "iopub.status.busy": "2023-06-03T00:15:39.070479Z",
     "iopub.status.idle": "2023-06-03T00:15:39.099136Z",
     "shell.execute_reply": "2023-06-03T00:15:39.096908Z",
     "shell.execute_reply.started": "2023-06-03T00:15:39.072294Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['intj', 'intp', 'entj', 'entp', 'infj', 'infp', 'enfj', 'enfp', 'istj', 'isfj', 'estj', 'esfj', 'istp', 'isfp', 'estp', 'esfp']\n",
    "id2label = {id:label for id,label in enumerate(labels)}\n",
    "label2id = {label:id for id,label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:40.649641Z",
     "iopub.status.busy": "2023-06-03T00:15:40.649085Z",
     "iopub.status.idle": "2023-06-03T00:15:40.663059Z",
     "shell.execute_reply": "2023-06-03T00:15:40.661627Z",
     "shell.execute_reply.started": "2023-06-03T00:15:40.649597Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, model_name=\"bert-base-uncased\"):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "        self.label = data['label'].apply(lambda l: label2id[l])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = self.tokenizer(text=self.data.iloc[idx].get('cleaned_text'), \n",
    "                             padding='max_length', \n",
    "                             max_length=500, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "        #F.one_hot(torch.tensor(self.label[idx]), num_classes=16).to(torch.float)\n",
    "        return {\n",
    "            'input_ids': res[\"input_ids\"].squeeze(), \n",
    "            'token_type_ids': res[\"token_type_ids\"].squeeze(), \n",
    "            'attention_mask': res[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.label[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:42.952067Z",
     "iopub.status.busy": "2023-06-03T00:15:42.951344Z",
     "iopub.status.idle": "2023-06-03T00:15:44.736252Z",
     "shell.execute_reply": "2023-06-03T00:15:44.735075Z",
     "shell.execute_reply.started": "2023-06-03T00:15:42.952020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1468003a86eb4420b6dba05db556e0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec37c716175d47eb863203647c078656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4504bf4e14d54af0a524cf3e5e8fba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207afdd8b884a25879b83d19db2c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = CustomTextDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:46.786573Z",
     "iopub.status.busy": "2023-06-03T00:15:46.786122Z",
     "iopub.status.idle": "2023-06-03T00:15:46.797330Z",
     "shell.execute_reply": "2023-06-03T00:15:46.795509Z",
     "shell.execute_reply.started": "2023-06-03T00:15:46.786536Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(ds)),\n",
    "    test_size=0.1,\n",
    ")\n",
    "train_split = Subset(ds, train_indices)\n",
    "test_split = Subset(ds, test_indices)\n",
    "\n",
    "train_batches = DataLoader(\n",
    "    train_split, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True,\n",
    "    drop_last = True\n",
    ")\n",
    "test_batches = DataLoader(test_split, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:56:46.144532Z",
     "iopub.status.busy": "2023-05-23T01:56:46.144191Z",
     "iopub.status.idle": "2023-05-23T01:56:46.148527Z",
     "shell.execute_reply": "2023-05-23T01:56:46.147567Z",
     "shell.execute_reply.started": "2023-05-23T01:56:46.144505Z"
    }
   },
   "outputs": [],
   "source": [
    "# ds = CustomTextDataset(data)\n",
    "# train_loader = DataLoader(\n",
    "#     ds, \n",
    "#     batch_size = 20, \n",
    "#     shuffle = True, \n",
    "#     num_workers = 0, \n",
    "#     pin_memory = True, \n",
    "#     drop_last = True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:50.913378Z",
     "iopub.status.busy": "2023-06-03T00:15:50.912862Z",
     "iopub.status.idle": "2023-06-03T00:15:50.923628Z",
     "shell.execute_reply": "2023-06-03T00:15:50.922402Z",
     "shell.execute_reply.started": "2023-06-03T00:15:50.913337Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, seq_length):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(768, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size*seq_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class BERTWithClassifierHead(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        # ClassifierHead is already defined.\n",
    "        self.classifier = ClassifierHead(20, num_classes, 500)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bert(**x)\n",
    "        x = x.last_hidden_state\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:15:53.460014Z",
     "iopub.status.busy": "2023-06-03T00:15:53.459311Z",
     "iopub.status.idle": "2023-06-03T00:15:56.861602Z",
     "shell.execute_reply": "2023-06-03T00:15:56.860637Z",
     "shell.execute_reply.started": "2023-06-03T00:15:53.459981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76da1e4362bd4f769883336d46688703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BERTWithClassifierHead(num_classes=16)\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 16, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T04:39:31.650275Z",
     "iopub.status.busy": "2023-05-19T04:39:31.649887Z",
     "iopub.status.idle": "2023-05-19T04:39:39.206206Z",
     "shell.execute_reply": "2023-05-19T04:39:39.205109Z",
     "shell.execute_reply.started": "2023-05-19T04:39:31.650236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16]) torch.Size([25, 16])\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# model.to(device)\n",
    "# batch = next(iter(train_batches))\n",
    "# X = {k: batch[k] for k in batch.keys() if k not in [\"label\"]}\n",
    "# y = batch[\"label\"]\n",
    "# X = {k: v.to(device) for k, v in X.items()}\n",
    "# y = y.to(device)\n",
    "# output = model(**X).logits\n",
    "# print(output.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T23:18:57.721446Z",
     "iopub.status.busy": "2023-05-27T23:18:57.720973Z",
     "iopub.status.idle": "2023-05-27T23:19:03.742185Z",
     "shell.execute_reply": "2023-05-27T23:19:03.741241Z",
     "shell.execute_reply.started": "2023-05-27T23:18:57.721408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTWithClassifierHead(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): ClassifierHead(\n",
       "    (rnn): RNN(768, 20, batch_first=True)\n",
       "    (linear): Linear(in_features=10000, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "lr = 5e-5\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Define Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer.\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "# optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# Define LR Scheduler.\n",
    "num_training_steps = epochs * len(train_batches)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T07:19:14.560212Z",
     "iopub.status.busy": "2023-05-19T07:19:14.559814Z",
     "iopub.status.idle": "2023-05-19T07:19:14.564758Z",
     "shell.execute_reply": "2023-05-19T07:19:14.563872Z",
     "shell.execute_reply.started": "2023-05-19T07:19:14.560180Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "# with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         batch = next(iter(train_loader))\n",
    "#         X = {k: batch[k] for k in batch.keys() if k not in [\"label\"]}\n",
    "#         y = batch[\"label\"]\n",
    "#         X = {k: v.to(device) for k, v in X.items()}\n",
    "#         y = y.to(device)\n",
    "#         model(X)\n",
    "# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T23:19:25.590327Z",
     "iopub.status.busy": "2023-05-27T23:19:25.589989Z",
     "iopub.status.idle": "2023-05-27T23:38:20.560295Z",
     "shell.execute_reply": "2023-05-27T23:38:20.559378Z",
     "shell.execute_reply.started": "2023-05-27T23:19:25.590298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b662f52c199c40e0ad4a9e7950da7e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 2.636\n",
      "[1,   100] loss: 2.600\n",
      "[1,   150] loss: 2.633\n",
      "[1,   200] loss: 2.577\n",
      "[1,   250] loss: 2.623\n",
      "[1,   300] loss: 2.608\n",
      "[2,    50] loss: 2.573\n",
      "[2,   100] loss: 2.574\n",
      "[2,   150] loss: 2.554\n",
      "[2,   200] loss: 2.586\n",
      "[2,   250] loss: 2.545\n",
      "[2,   300] loss: 2.569\n",
      "[3,    50] loss: 2.555\n",
      "[3,   100] loss: 2.566\n",
      "[3,   150] loss: 2.486\n",
      "[3,   200] loss: 2.542\n",
      "[3,   250] loss: 2.516\n",
      "[3,   300] loss: 2.523\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_batches, 0):\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # Unpack the dictionary.\n",
    "        X = {k: batch[k] for k in batch.keys() if k not in \"labels\"}\n",
    "        y = batch[\"labels\"]\n",
    "\n",
    "#         One step.\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        scaler.update()\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 45 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print(\"Finished Training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T02:07:33.023920Z",
     "iopub.status.busy": "2023-05-23T02:07:33.023539Z",
     "iopub.status.idle": "2023-05-23T02:09:17.427928Z",
     "shell.execute_reply": "2023-05-23T02:09:17.426886Z",
     "shell.execute_reply.started": "2023-05-23T02:07:33.023891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0= tensor(4.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1= tensor(3.9684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2= tensor(3.6470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3= tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4= tensor(2.9921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5= tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6= tensor(2.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7= tensor(2.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8= tensor(2.5209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9= tensor(2.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10= tensor(2.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11= tensor(2.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12= tensor(2.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13= tensor(2.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14= tensor(2.3696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15= tensor(2.3812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16= tensor(2.3550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17= tensor(2.3861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18= tensor(2.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19= tensor(2.3827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20= tensor(2.4145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21= tensor(2.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22= tensor(2.3919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23= tensor(2.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24= tensor(2.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25= tensor(2.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26= tensor(2.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27= tensor(2.3599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28= tensor(2.3314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29= tensor(2.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30= tensor(2.3769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31= tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32= tensor(2.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33= tensor(2.2967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34= tensor(2.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35= tensor(2.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36= tensor(2.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37= tensor(2.3331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38= tensor(2.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39= tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "40= tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "41= tensor(2.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "42= tensor(2.3421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "43= tensor(2.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "44= tensor(2.3814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "45= tensor(2.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "46= tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "47= tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "48= tensor(2.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "49= tensor(2.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "50= tensor(2.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "51= tensor(2.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "52= tensor(2.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "53= tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "54= tensor(2.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "55= tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "56= tensor(2.3356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "57= tensor(2.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "58= tensor(2.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "59= tensor(2.3140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "60= tensor(2.3807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "61= tensor(2.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "62= tensor(2.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "63= tensor(2.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "64= tensor(2.3488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "65= tensor(2.3224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "66= tensor(2.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "67= tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "68= tensor(2.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "69= tensor(2.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "70= tensor(2.3021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "71= tensor(2.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "72= tensor(2.3908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "73= tensor(2.4052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "74= tensor(2.2917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "75= tensor(2.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "76= tensor(2.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "77= tensor(2.3159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "78= tensor(2.3135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "79= tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "80= tensor(2.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "81= tensor(2.3392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "82= tensor(2.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "83= tensor(2.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "84= tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "85= tensor(2.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "86= tensor(2.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "87= tensor(2.3237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "88= tensor(2.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "89= tensor(2.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "90= tensor(2.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "91= tensor(2.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "92= tensor(2.2652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "93= tensor(2.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "94= tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "95= tensor(2.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "96= tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "97= tensor(2.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "98= tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "99= tensor(2.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "batch = next(iter(train_batches))\n",
    "    \n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "# Unpack the dictionary.\n",
    "X = {k: batch[k] for k in batch.keys() if k not in \"labels\"}\n",
    "y = batch[\"labels\"]\n",
    "for epoch in range(100):\n",
    "\n",
    "#         One step.\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "            \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    lr_scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    scaler.update()\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "    print(f'{epoch}=', loss)\n",
    "            \n",
    "print(\"Finished Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T00:11:17.805913Z",
     "iopub.status.busy": "2023-05-28T00:11:17.805552Z",
     "iopub.status.idle": "2023-05-28T00:11:18.936764Z",
     "shell.execute_reply": "2023-05-28T00:11:18.935413Z",
     "shell.execute_reply.started": "2023-05-28T00:11:17.805885Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/mbti.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:16:14.904774Z",
     "iopub.status.busy": "2023-06-03T00:16:14.904430Z",
     "iopub.status.idle": "2023-06-03T00:16:21.480476Z",
     "shell.execute_reply": "2023-06-03T00:16:21.479434Z",
     "shell.execute_reply.started": "2023-06-03T00:16:14.904747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTWithClassifierHead(num_classes=16)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=16)\n",
    "model.load_state_dict(torch.load('/kaggle/working/mbti.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:35:08.403165Z",
     "iopub.status.busy": "2023-06-03T00:35:08.402554Z",
     "iopub.status.idle": "2023-06-03T00:35:08.586918Z",
     "shell.execute_reply": "2023-06-03T00:35:08.585926Z",
     "shell.execute_reply.started": "2023-06-03T00:35:08.403131Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "res = tokenizer(text=\"this is some text hello hello hello\", \n",
    "                             padding='max_length', \n",
    "                             max_length=500, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:41:07.089231Z",
     "iopub.status.busy": "2023-06-03T00:41:07.088872Z",
     "iopub.status.idle": "2023-06-03T00:41:08.114778Z",
     "shell.execute_reply": "2023-06-03T00:41:08.113631Z",
     "shell.execute_reply.started": "2023-06-03T00:41:07.089202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8819,  1.4050,  0.1773,  0.3725,  1.2178,  1.7634,  0.0153,  0.8813,\n",
      "         -0.2533, -0.4657, -1.7859, -1.7720, -0.3982,  0.2173, -1.5934, -0.8718]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(res)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:42:08.167718Z",
     "iopub.status.busy": "2023-06-03T00:42:08.167289Z",
     "iopub.status.idle": "2023-06-03T00:42:08.181637Z",
     "shell.execute_reply": "2023-06-03T00:42:08.180429Z",
     "shell.execute_reply.started": "2023-06-03T00:42:08.167688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0927, 0.1564, 0.0458, 0.0557, 0.1297, 0.2238, 0.0390, 0.0927, 0.0298,\n",
      "         0.0241, 0.0064, 0.0065, 0.0258, 0.0477, 0.0078, 0.0161]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "scaled = m(output)\n",
    "print(scaled)\n",
    "prediction = torch.argmax(scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T00:47:05.421704Z",
     "iopub.status.busy": "2023-06-03T00:47:05.421266Z",
     "iopub.status.idle": "2023-06-03T00:47:05.428465Z",
     "shell.execute_reply": "2023-06-03T00:47:05.427440Z",
     "shell.execute_reply.started": "2023-06-03T00:47:05.421673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T04:59:11.722795Z",
     "iopub.status.busy": "2023-05-19T04:59:11.722432Z",
     "iopub.status.idle": "2023-05-19T04:59:42.741499Z",
     "shell.execute_reply": "2023-05-19T04:59:42.740571Z",
     "shell.execute_reply.started": "2023-05-19T04:59:11.722766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 16 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_batches:\n",
    "        X = {k: batch[k] for k in batch.keys() if k not in \"label\"}\n",
    "        y = batch[\"label\"]\n",
    "\n",
    "        X = {k: v.to(device) for k, v in X.items()}\n",
    "        y = y.to(device)\n",
    "\n",
    "        outputs = model(**X).logits\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, actual = torch.max(y, 1)\n",
    "\n",
    "        total += actual.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "    \n",
    "print(f'Accuracy of the model: {100 * correct // total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T05:33:02.750103Z",
     "iopub.status.busy": "2023-05-19T05:33:02.749744Z",
     "iopub.status.idle": "2023-05-19T05:33:33.686290Z",
     "shell.execute_reply": "2023-05-19T05:33:33.685427Z",
     "shell.execute_reply.started": "2023-05-19T05:33:02.750077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.21335168616655195}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in test_batches:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    actual = torch.argmax(batch['labels'], dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=actual)\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T05:31:30.332965Z",
     "iopub.status.busy": "2023-05-19T05:31:30.332590Z",
     "iopub.status.idle": "2023-05-19T05:31:30.341106Z",
     "shell.execute_reply": "2023-05-19T05:31:30.340065Z",
     "shell.execute_reply.started": "2023-05-19T05:31:30.332937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  0,  3,  8,  7, 14,  5,  1,  4,  1,  4,  4,  5,  6,  0,  5,  0,  7,\n",
      "         1,  6,  7, 10,  0, 14,  1], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
